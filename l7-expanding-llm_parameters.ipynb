{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de529e8-3891-4f47-8585-65b92b80bbf7",
   "metadata": {},
   "source": [
    "# Expanding: \n",
    "\n",
    "It mens taking a piece of text and generate a longer piece of this text. So, in this lesson, you will generate customer service emails that are tailored to each customer's review.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1535183",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3995263b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, HTML  # to see better the output text\n",
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "739d2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    \"\"\"Helpful function to get prediction using the OpenAI library version `1.0.0`\"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12fa849",
   "metadata": {},
   "source": [
    "**Note**: In June 2023, OpenAI updated gpt-3.5-turbo. The results you see in the notebook may be slightly different than those in the video. Some of the prompts have also been slightly modified to product the desired results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ceea77-990a-4c64-bb49-3ba65eb155d2",
   "metadata": {},
   "source": [
    "## Customize the automated reply to a customer email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30c4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = (\n",
    "    \"So, they still had the 17 piece system on seasonal \"\n",
    "    \"sale for around $49 in the month of November, about \"\n",
    "    \"half off, but for some reason (call it price gouging) \"\n",
    "    \"around the second week of December the prices all went \"\n",
    "    \"up to about anywhere from between $70-$89 for the same \"\n",
    "    \"system. And the 11 piece system went up around $10 or \"\n",
    "    \"so in price also from the earlier sale price of $29. \"\n",
    "    \"So it looks okay, but if you look at the base, the part \"\n",
    "    \"where the blade locks into place doesnâ€™t look as good \"\n",
    "    \"as in previous editions from a few years ago, but I \"\n",
    "    \"plan to be very gentle with it (example, I crush \"\n",
    "    \"very hard items like beans, ice, rice, etc. in the  \"\n",
    "    \"blender first then pulverize them in the serving size \"\n",
    "    \"I want in the blender then switch to the whipping \"\n",
    "    \"blade for a finer flour, and use the cross cutting blade \"\n",
    "    \"first when making smoothies, then use the flat blade \"\n",
    "    \"if I need them finer/less pulpy). Special tip when making \"\n",
    "    \"smoothies, finely cut and freeze the fruits and \"\n",
    "    \"vegetables (if using spinach-lightly stew soften the  \"\n",
    "    \"spinach then freeze until ready for use-and if making \"\n",
    "    \"sorbet, use a small to medium sized food processor)  \"\n",
    "    \"that you plan to use that way you can avoid adding so \"\n",
    "    \"much ice if at all-when making your smoothie. \"\n",
    "    \"After about a year, the motor was making a funny noise. \"\n",
    "    \"I called customer service but the warranty expired \"\n",
    "    \"already, so I had to buy another one. FYI: The overall \"\n",
    "    \"quality has gone done in these types of products, so \"\n",
    "    \"they are kind of counting on brand recognition and \"\n",
    "    \"consumer loyalty to maintain sales. Got it in about \"\n",
    "    \"two days \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5403f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Dear valued customer,\n",
       "\n",
       "Thank you for taking the time to share your detailed feedback with us. We are truly sorry to hear about the issues you experienced with the pricing changes and the quality of the product. We apologize for any inconvenience this may have caused you.\n",
       "\n",
       "If you have any further concerns or would like to discuss this matter further, please do not hesitate to reach out to our customer service team. They will be more than happy to assist you.\n",
       "\n",
       "We appreciate your feedback as it helps us improve our products and services for all our customers.\n",
       "\n",
       "Thank you again for your review.\n",
       "\n",
       "AI customer agent"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "HTML(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093f391",
   "metadata": {},
   "source": [
    "## Changinf the temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cfc00c",
   "metadata": {},
   "source": [
    "The temperature controls the amount of randomness in the AI's responses. A high temperature produces more unpredictable and creative results, while a low temperature produces more deterministic and conservative output.\n",
    "\n",
    "![temperature_explication](resources/temperature_explication.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55605ee0-118c-4c46-a917-4981a43fcad3",
   "metadata": {},
   "source": [
    "## Remind the model to use details from the customer's email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d5ea7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Dear valued customer,\n",
       "\n",
       "Thank you for taking the time to share your detailed feedback. We apologize for any inconvenience you experienced with the price changes and the quality of the product. We strive to provide the best experience for our customers, and we regret to hear that you were not completely satisfied.\n",
       "\n",
       "If you have any further concerns or would like to discuss this matter further, please feel free to reach out to our customer service team for assistance. We are here to help and ensure that you are content with your purchases.\n",
       "\n",
       "Thank you for your understanding and for being a loyal customer. We appreciate your feedback as it helps us improve our products and services.\n",
       "\n",
       "AI customer agent"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for their review.\n",
    "If the sentiment is negative, apologize and suggest that they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0.7)\n",
    "HTML(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e36bc3",
   "metadata": {},
   "source": [
    "## Other importants parameters \n",
    "\n",
    "https://medium.com/@dixnjakindah/top-p-temperature-and-other-parameters-1a53d2f8d7d7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2575ee1b",
   "metadata": {},
   "source": [
    "### **Top p**\n",
    "Top p, also known as nucleus sampling, is another hyperparameter that controls the randomness of language model output.\n",
    "\n",
    "It sets a threshold probability and selects the top tokens whose cumulative probability exceeds the threshold. The model then randomly samples from this set of tokens to generate output. This method can produce more diverse and interesting output than traditional methods that randomly sample the entire vocabulary.\n",
    "\n",
    "For example, if you set top p to 0.9, the model will only consider the most likely words that make up 90% of the probability mass.\n",
    "\n",
    "\n",
    "### **Token length**\n",
    "This is the number of words or characters in a sequence or text that is fed to the LLM.\n",
    "\n",
    "It varies depending on the language and the tokenization method used for the particular LLM.\n",
    "\n",
    "\n",
    "### **Max tokens**\n",
    "This is the maximum number of tokens that the LLM generates.\n",
    "\n",
    "Within this, is the token limit; the maximum number of tokens that can be used in the prompt and the completion of the model. Determined by the architecture of the model LLM, it refers to the maximum tokens that can be processed at once.\n",
    "\n",
    "The computational cost and the memory requirements are directly proportional to the max tokens. Set a longer max token, and you will have greater context and coherent output text. Set a shorter max token, and you will use less memory and have a faster response but your output is prone to errors and inconsistencies.\n",
    "\n",
    "### **Stop tokens**\n",
    "In simple terms, it is the length of the output or response of an LLM.\n",
    "\n",
    "So it signifies the end of a sequence in terms of either a paragraph or a sentence.\n",
    "\n",
    "Similar to max tokens, the inference budget is reduced when the stop tokens are set low."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
